{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Universidades:\n",
    "\n",
    "    # Creamos la clase sin método constructor, ya que no necesitamos realizar ninguna inicialización especial.\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 1. Extracción\n",
    "\n",
    "    def api(self, paises):\n",
    "\n",
    "        \"\"\"Esta función recibe un único parámetro, que será un string o una lista de strings con el nombre del país o países (en inglés) de los que se quiere\n",
    "        obtener información. Se realizará la extracción de los datos de los países indicados, y devolverá un DataFrame\n",
    "        con la información obtenida. En caso de que hubiera algún error, devolverá el número del error y el motivo.\"\"\"\n",
    "\n",
    "        if isinstance(paises, str): # Comprueba si el parámetro introducido es un string. \n",
    "\n",
    "            url = f\"http://universities.hipolabs.com/search?country={paises}\" \n",
    "\n",
    "            response = requests.get(url)\n",
    "\n",
    "            code = response.status_code # Devuelve el código de la extracción de datos\n",
    "\n",
    "            reason = response.reason # Devuelve el motivo.\n",
    "\n",
    "            if code == 200: # Comprueba que el código de la extracción sea 200, es decir, que haya ocurrido correctamente.\n",
    "\n",
    "                print(f\"Información de {paises} obtenida correctamente, se va a convertir en DataFrame.\")\n",
    "\n",
    "                df =  pd.json_normalize(response.json())\n",
    "\n",
    "                return df # Devuelve el DataFrame con la información del país indicado. \n",
    "            \n",
    "            else: \n",
    "                return f\"Error: {code}, {reason}.\" # Si no, devuelve el código de error y el motivo.\n",
    "        \n",
    "        elif isinstance(paises, list):  # Comprueba si el parámetro introducido es una lista.\n",
    "\n",
    "            df_universidades = pd.DataFrame() #Se crea un DataFrame vacío para ir uniendo los resultados por cada país de la lista introducida.\n",
    "\n",
    "            for pais in paises: \n",
    "\n",
    "                url = f\"http://universities.hipolabs.com/search?country={pais}\"\n",
    "\n",
    "                response = requests.get(url) \n",
    "\n",
    "                code = response.status_code # Devuelve el código de la extracción de datos\n",
    "\n",
    "                reason = response.reason # Devuelve el motivo.\n",
    "\n",
    "                if code == 200: # Comprueba que el código de la extracción sea 200, es decir, que haya ocurrido correctamente.\n",
    "\n",
    "                    print(f\"Información de {pais} obtenida correctamente, se va a convertir en DataFrame.\")\n",
    "\n",
    "                    df =  pd.json_normalize(response.json())\n",
    "\n",
    "                    df_universidades = pd.concat([df_universidades, df], axis = 0) # Se unen los resultados en el DataFrame creado\n",
    "\n",
    "                else: \n",
    "                    return f\"Error: {code}, {reason}.\"\n",
    "                \n",
    "            \n",
    "            return df_universidades # Devuelve el DataFrame con la información de los paises indicados si se ha podido crear. Fuera del bucle para\n",
    "                                    # que se pueda completar el bucle. \n",
    "        \n",
    "        else:\n",
    "            print(\"Por favor, introduzca un único país o una lista de paises (en inglés).\")\n",
    "\n",
    "    \n",
    "    # 2. Limpieza\n",
    "\n",
    "    def limpieza(self, dataframe):\n",
    "\n",
    "        \"\"\"Esta función recibe como parámetro el nombre del dataframe a limpiar.\n",
    "            Devuelve el dataframe con el nombre de las columnas cambiadas (\"-\" ahora es \"_\"), y elimina una columna redundante. Además,\n",
    "            realiza el explode a la columna \"web_pages, elimina los duplicados de la columna  \"name\", imputa los nulos de\n",
    "            la columna \"state_province\" por la categoría \"Unknown\". Asimismo, cambia los estados por el nombre completo. \n",
    "            Devuelve el dataframe con los datos aplicados. \"\"\"\n",
    "\n",
    "        nuevas_columnas = {col : col.replace(\"-\", \"_\") for col in dataframe.columns} # Se crea un diccionario con los nombres antiguos como key, y \n",
    "                                                                                    #los nuevos nombres como value.\n",
    "\n",
    "        dataframe.rename(columns = nuevas_columnas, inplace = True) # Se realiza el cambio del nombre de las columnas.\n",
    "            \n",
    "        dataframe.drop(\"domains\", axis = 1, inplace = True) # Se elimina la columna de domains.\n",
    "\n",
    "        dataframe = dataframe.explode(\"web_pages\") # Se realiza el explode para la columna de \"web_pages\"\n",
    "\n",
    "        dataframe.drop_duplicates(subset = \"name\", inplace = True) # Se eliminan los duplicados en la columna \"name\"\n",
    "\n",
    "        dataframe[\"state_province\"].fillna(\"Unknown\", inplace = True)\n",
    "\n",
    "        dataframe[\"state_province\"] = dataframe[\"state_province\"].replace(\"NV\", \"Nevada\").replace(\"TX\", \"Texas\").replace(\"IN\", \"Indianapolis\").replace(\"CA\", \"California\").replace(\"VA\", \"Virginia\").replace(\"NY\", \"New York\")\n",
    "            \n",
    "        dataframe[\"state_province\"] = dataframe[\"state_province\"].replace(\"New York, NY\", \"New York\").replace(\"MI\", \"Michigan\").replace(\"GA\", \"Georgia\").replace(\"ND\", \"North Dakota\").replace(\"Ciudad Autónoma de Buenos Aires\", \"Buenos Aires\")\n",
    "        \n",
    "        # Se realizan varias modificaciones a la columna \"state_province\", imputando los nulos por una nueva categoría y reemplazando los nombres de estados\n",
    "        # por otros nombres más claros. El replace se podría haber hecho una única línea de código, pero quedaba muy larga, así que he \n",
    "        # optado por partirla en dos. \n",
    "        \n",
    "        dataframe[\"name\"] = dataframe[\"name\"].str.replace('\"', '') # Hay algunas universidades que tienen dobles comillas en sus nombres, lo que impide su inserción en la base de datos. \n",
    "                                                                    #Lo solucionamos aquí para evitar problemas en la futura inserción\n",
    "    \n",
    "\n",
    "        return dataframe # Se devuelve el dataframe con los cambios aplicados \n",
    "        \n",
    "    def sacar_coordenadas(self, dataframe):\n",
    "        \n",
    "        \"\"\"Esta función recibe dos parámetros, que es el nombre del dataframe y el nombre de la columna sobre la que se quieren sacar las coordenadas.\n",
    "        Se utiliza la librería de Geopy para conseguir la latitud y la longitud de los lugares indicados. \n",
    "        Devuelve el DataFrame con dos columnas nuevas, \"lat\" y \"long\", que contienen las coordenadas en función del lugar de la columna indicada.\"\"\"\n",
    "\n",
    "        lista_estados = list(dataframe[\"state_province\"].unique()) # Primero, se crea una lista con los valores únicos de esa columna.\n",
    "\n",
    "        df_localizacion = pd.DataFrame(columns = [\"state_province\", \"lat\", \"long\"]) # Se crea un datagrame vacío para poder introducir los datos. \n",
    "\n",
    "        for estado in lista_estados: \n",
    "\n",
    "            if estado != \"Unknown\":  \n",
    "                geo = Nominatim(user_agent = \"nombre\")\n",
    "                localizacion = geo.geocode(f\"{estado}\")\n",
    "                state = f\"{estado}\"\n",
    "                latitud = localizacion[1][0]\n",
    "                longitud = localizacion[1][1]\n",
    "\n",
    "                df_localizacion.loc[len(df_localizacion.index)] = [state, latitud, longitud] #Se añaden los datos sacados de Geopy en la última fila del DataFrame creado.\n",
    "            \n",
    "            else: # Si el estado/lugar entra en la categoría creada previamente de \"Unknown\", entonces las coordenadas se convertirán a un nulo de NumPY.\n",
    "                \n",
    "                state = f\"{estado}\"\n",
    "                latitud = np.nan\n",
    "                longitud = np.nan\n",
    "                \n",
    "                df_localizacion.loc[len(df_localizacion.index)] = [state, latitud, longitud]\n",
    "            \n",
    "        dataframe = pd.merge(dataframe, df_localizacion, on = \"state_province\", how = \"left\")\n",
    "\n",
    "        return dataframe\n",
    "    \n",
    "    def guardar_df(self, dataframe, ruta_nombre):\n",
    "\n",
    "        \"\"\"Esta función recibe dos parámetros, que son el nombre del dataframe a guardar y la ruta donde se quiere guardar. \n",
    "        Guarda el archivo tanto en .pkl como en .csv\"\"\"\n",
    "\n",
    "        dataframe.to_csv(f\"{ruta_nombre}.csv\")\n",
    "        dataframe.to_pickle(f\"{ruta_nombre}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Universidades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_paises = [\"Argentina\", \"Canada\", \"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información de Argentina obtenida correctamente, se va a convertir en DataFrame.\n",
      "Información de Canada obtenida correctamente, se va a convertir en DataFrame.\n",
      "Información de United States obtenida correctamente, se va a convertir en DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df_universidades = df.api(lista_paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "      <th>state-province</th>\n",
       "      <th>name</th>\n",
       "      <th>domains</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[http://www.atlantida.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Atlantida Argentina</td>\n",
       "      <td>[atlantida.edu.ar]</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[http://www.austral.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Austral Buenos Aires</td>\n",
       "      <td>[austral.edu.ar]</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[http://www.caece.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Universidad CAECE, Buenos Aires</td>\n",
       "      <td>[caece.edu.ar]</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[http://www.cema.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Instituto Universitario CEMA</td>\n",
       "      <td>[cema.edu.ar]</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[http://www.iese.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Instituto de Enseñanza Superior del Ejército</td>\n",
       "      <td>[iese.edu.ar]</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>[https://csu.edu]</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>Chicago State University</td>\n",
       "      <td>[csu.edu]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>[https://csupueblo.edu]</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>Colorado State University-Pueblo</td>\n",
       "      <td>[csupueblo.edu]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>[https://bau.edu/]</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>Bay Atlantic University</td>\n",
       "      <td>[bau.edu]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>[https://www.siena.edu/]</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>Siena College</td>\n",
       "      <td>[siena.edu]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>[https://txwes.edu/]</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>Texas Wesleyan University</td>\n",
       "      <td>[txwes.edu]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5008 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           web_pages alpha_two_code  \\\n",
       "0     [http://www.atlantida.edu.ar/]             AR   \n",
       "1       [http://www.austral.edu.ar/]             AR   \n",
       "2         [http://www.caece.edu.ar/]             AR   \n",
       "3          [http://www.cema.edu.ar/]             AR   \n",
       "4          [http://www.iese.edu.ar/]             AR   \n",
       "...                              ...            ...   \n",
       "4531               [https://csu.edu]             US   \n",
       "4532         [https://csupueblo.edu]             US   \n",
       "4533              [https://bau.edu/]             US   \n",
       "4534        [https://www.siena.edu/]             US   \n",
       "4535            [https://txwes.edu/]             US   \n",
       "\n",
       "                       state-province  \\\n",
       "0                        Buenos Aires   \n",
       "1                        Buenos Aires   \n",
       "2     Ciudad Autónoma de Buenos Aires   \n",
       "3     Ciudad Autónoma de Buenos Aires   \n",
       "4     Ciudad Autónoma de Buenos Aires   \n",
       "...                               ...   \n",
       "4531                             None   \n",
       "4532                             None   \n",
       "4533                             None   \n",
       "4534                             None   \n",
       "4535                             None   \n",
       "\n",
       "                                              name             domains  \\\n",
       "0                  Universidad Atlantida Argentina  [atlantida.edu.ar]   \n",
       "1                 Universidad Austral Buenos Aires    [austral.edu.ar]   \n",
       "2                  Universidad CAECE, Buenos Aires      [caece.edu.ar]   \n",
       "3                     Instituto Universitario CEMA       [cema.edu.ar]   \n",
       "4     Instituto de Enseñanza Superior del Ejército       [iese.edu.ar]   \n",
       "...                                            ...                 ...   \n",
       "4531                      Chicago State University           [csu.edu]   \n",
       "4532              Colorado State University-Pueblo     [csupueblo.edu]   \n",
       "4533                       Bay Atlantic University           [bau.edu]   \n",
       "4534                                 Siena College         [siena.edu]   \n",
       "4535                     Texas Wesleyan University         [txwes.edu]   \n",
       "\n",
       "            country  \n",
       "0         Argentina  \n",
       "1         Argentina  \n",
       "2         Argentina  \n",
       "3         Argentina  \n",
       "4         Argentina  \n",
       "...             ...  \n",
       "4531  United States  \n",
       "4532  United States  \n",
       "4533  United States  \n",
       "4534  United States  \n",
       "4535  United States  \n",
       "\n",
       "[5008 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_universidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_universidades = df.limpieza(df_universidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_universidades = df.sacar_coordenadas(df_universidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.guardar_df(df_universidades, \"../data/universidades\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
